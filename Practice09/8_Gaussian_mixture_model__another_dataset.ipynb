{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f70cc7",
   "metadata": {},
   "source": [
    "# Prepare the environment and collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa72d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 01:32:14 WARN Utils: Your hostname, m0 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "22/10/19 01:32:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 01:32:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/10/19 01:32:24 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- pdays: string (nullable = true)\n",
      " |-- previous: string (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Linear regression\").getOrCreate()\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.functions import mean, col\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "file_location = \"bank_deposit.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"False\"\n",
    "first_row_is_header = \"True\"\n",
    "df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".option(\"header\", first_row_is_header) \\\n",
    ".load(file_location)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f668d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "|age|job       |marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "|59 |admin.    |married|secondary|no     |2343   |yes    |no  |unknown|5  |may  |1042    |1       |-1   |0       |unknown |yes    |\n",
      "|56 |admin.    |married|secondary|no     |45     |no     |no  |unknown|5  |may  |1467    |1       |-1   |0       |unknown |yes    |\n",
      "|41 |technician|married|secondary|no     |1270   |yes    |no  |unknown|5  |may  |1389    |1       |-1   |0       |unknown |yes    |\n",
      "|55 |services  |married|secondary|no     |2476   |yes    |no  |unknown|5  |may  |579     |1       |-1   |0       |unknown |yes    |\n",
      "|54 |admin.    |married|tertiary |no     |184    |no     |no  |unknown|5  |may  |673     |2       |-1   |0       |unknown |yes    |\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d452fc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'int'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'string'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('deposit', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "#Identifying and assigning lists of variables\n",
    "float_vars=['age', 'balance', 'duration','campaign','pdays','previous']\n",
    "#Converting variables\n",
    "for column in float_vars:\n",
    " df=df.withColumn(column,df[column].cast(IntegerType()))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2507759",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b222e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(df, CatCols, continuousCols, labelCol):\n",
    "  \n",
    "  indexers = [StringIndexer(inputCol=c, \n",
    "                            outputCol=\"{0}_indexed\".format(c)) for c in CatCols]\n",
    "\n",
    "  encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "              outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "              for indexer in indexers]\n",
    "\n",
    "\n",
    "  v = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                              + continuousCols, outputCol=\"features\")\n",
    "  \n",
    "  indexer = StringIndexer(inputCol=labelCol, outputCol='indexedLabel')\n",
    "\n",
    "  pipeline = Pipeline(stages = indexers + encoders + [v ] + [indexer])\n",
    "\n",
    "  model=pipeline.fit(df)\n",
    "    \n",
    "  data = model.transform(df)\n",
    "\n",
    "  data =  data.withColumn('label', col(labelCol))\n",
    "  \n",
    "  return  data.select('features', \n",
    "                     'indexedLabel', \n",
    "                     'label'), StringIndexer(inputCol='label').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b917726a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 01:33:34 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CatCols = ['job', 'marital', 'education', \n",
    "                      'default', 'housing', 'loan', \n",
    "                      'contact', 'poutcome']\n",
    "\n",
    "NumCols = ['age', 'balance', 'duration', \n",
    "               'campaign', 'pdays', 'previous']\n",
    "\n",
    "(df, labelindexer) = data_transformation(df, CatCols, NumCols, 'deposit')\n",
    "\n",
    "df.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b70777dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------------------+\n",
      "|            features|indexedLabel|label|     indexedFeatures|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|(30,[4,11,13,16,1...|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|(30,[3,11,14,16,1...|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|(30,[0,12,14,16,2...|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|(30,[0,11,14,16,2...|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|(30,[5,13,16,18,2...|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|(30,[4,12,13,16,1...|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=4).fit(df)\n",
    "\n",
    "featureIndexer.transform(df).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78e762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 35:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ccb8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data splitting\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=10)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "trainingData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd5536",
   "metadata": {},
   "source": [
    "# Gaussian mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecb589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 164:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "train_df= df.selectExpr(\"features as features\")\n",
    "\n",
    "gmm = GaussianMixture(k=3, featuresCol='features')\n",
    "gmm_model = gmm.fit(train_df)\n",
    "gmm_model.gaussiansDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606803ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
