{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dccc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/30 14:42:55 WARN Utils: Your hostname, m0 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "22/10/30 14:42:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/30 14:42:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/30 14:43:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/30 14:43:04 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/10/30 14:43:04 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|News                                                                                                                                                                                                                                               |Sentiment|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|- BEIJING XFN-ASIA - Hong Kong-listed Standard Chartered Bank said it has signed a China mobile phone dealer financing agreement with Nokia , making it the first foreign bank to offer financing to the country 's small and medium enterprise -LR|1        |\n",
      "|- Operating profit rose by 26.9 % to EUR 105.8 ( 83.4 ) million .                                                                                                                                                                                  |1        |\n",
      "|- Provides summary of the medical equipment pipeline products that the company is developing .                                                                                                                                                     |0        |\n",
      "|- So , the sales growth of cars considerably influence on the tires market '' .                                                                                                                                                                    |0        |\n",
      "|- UPM-Kymmene upgraded to ` in-line ' from ` underperform ' by Goldman Sachs .                                                                                                                                                                     |1        |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('9_NPL3_Sentiment Analysis ').getOrCreate()\n",
    "\n",
    "file_location = \"9_financial_news.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "df = spark.read.format(file_type) \\\n",
    " .option(\"inferSchema\", infer_schema) \\\n",
    " .option(\"header\", first_row_is_header) \\\n",
    " .option(\"sep\", delimiter) \\\n",
    " .load(file_location)\n",
    "df.show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13746750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "962"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd41367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non ASCII characters\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import re\n",
    "\n",
    "# remove non ASCII characters\n",
    "def strip_non_ascii(data_str):\n",
    "    ''' Returns the string without non ASCII characters'''\n",
    "    stripped = (c for c in data_str if 0 < ord(c) < 127)\n",
    "    return ''.join(stripped)\n",
    "# setup pyspark udf function\n",
    "strip_non_ascii_udf = udf(strip_non_ascii, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f2419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                News|Sentiment|       News_non_asci|\n",
      "+--------------------+---------+--------------------+\n",
      "|- BEIJING XFN-ASI...|        1|- BEIJING XFN-ASI...|\n",
      "|- Operating profi...|        1|- Operating profi...|\n",
      "|- Provides summar...|        0|- Provides summar...|\n",
      "|- So , the sales ...|        0|- So , the sales ...|\n",
      "|- UPM-Kymmene upg...|        1|- UPM-Kymmene upg...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the function:\n",
    "df = df.withColumn('News_non_asci',strip_non_ascii_udf(df['News']))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960817da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed abbreviation\n",
    "def fix_abbreviation(data_str):\n",
    "    data_str = data_str.lower()\n",
    "    data_str = re.sub(r'\\bthats\\b', 'that is', data_str)\n",
    "    data_str = re.sub(r'\\bive\\b', 'i have', data_str)\n",
    "    data_str = re.sub(r'\\bim\\b', 'i am', data_str)\n",
    "    data_str = re.sub(r'\\bya\\b', 'yeah', data_str)\n",
    "    data_str = re.sub(r'\\bcant\\b', 'can not', data_str)\n",
    "    data_str = re.sub(r'\\bdont\\b', 'do not', data_str)\n",
    "    data_str = re.sub(r'\\bwont\\b', 'will not', data_str)\n",
    "    data_str = re.sub(r'\\bid\\b', 'i would', data_str)\n",
    "    data_str = re.sub(r'wtf', 'what the fuck', data_str)\n",
    "    data_str = re.sub(r'\\bwth\\b', 'what the hell', data_str)\n",
    "    data_str = re.sub(r'\\br\\b', 'are', data_str)\n",
    "    data_str = re.sub(r'\\bu\\b', 'you', data_str)\n",
    "    data_str = re.sub(r'\\bk\\b', 'OK', data_str)\n",
    "    data_str = re.sub(r'\\bsux\\b', 'sucks', data_str)\n",
    "    data_str = re.sub(r'\\bno+\\b', 'no', data_str)\n",
    "    data_str = re.sub(r'\\bcoo+\\b', 'cool', data_str)\n",
    "    data_str = re.sub(r'rt\\b', '', data_str)\n",
    "    data_str = data_str.strip()\n",
    "    return data_str\n",
    "\n",
    "fix_abbreviation_udf = udf(fix_abbreviation, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121ac190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+\n",
      "|                News|Sentiment|       News_non_asci|   News_fixed_abbrev|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|- BEIJING XFN-ASI...|        1|- BEIJING XFN-ASI...|- beijing xfn-asi...|\n",
      "|- Operating profi...|        1|- Operating profi...|- operating profi...|\n",
      "|- Provides summar...|        0|- Provides summar...|- provides summar...|\n",
      "|- So , the sales ...|        0|- So , the sales ...|- so , the sales ...|\n",
      "|- UPM-Kymmene upg...|        1|- UPM-Kymmene upg...|- upm-kymmene upg...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('News_fixed_abbrev',fix_abbreviation_udf(df['News']))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579a99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(data_str):\n",
    "    # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    mention_re = re.compile('@(\\w+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove @mentions\n",
    "    data_str = mention_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 1 characters\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    # remove unwanted space, *.split() will automatically split on\n",
    "    # whitespace and discard duplicates, the \" \".join() joins the\n",
    "    # resulting list into one string.\n",
    "    return \" \".join(cleaned_str.split())\n",
    "# setup pyspark udf function\n",
    "remove_features_udf = udf(remove_features, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b095672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|                News|Sentiment|       News_non_asci|   News_fixed_abbrev|        News_Cleaned|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|- BEIJING XFN-ASI...|        1|- BEIJING XFN-ASI...|- beijing xfn-asi...|beijing xfn asia ...|\n",
      "|- Operating profi...|        1|- Operating profi...|- operating profi...|operating profit ...|\n",
      "|- Provides summar...|        0|- Provides summar...|- provides summar...|provides summary ...|\n",
      "|- So , the sales ...|        0|- So , the sales ...|- so , the sales ...|so the sales grow...|\n",
      "|- UPM-Kymmene upg...|        1|- UPM-Kymmene upg...|- upm-kymmene upg...|upm kymmene upgra...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('News_Cleaned',remove_features_udf(df['News_fixed_abbrev']))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac407ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in ./anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in ./anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.3.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "|                News|Sentiment|       News_non_asci|   News_fixed_abbrev|        News_Cleaned|sentiment_score|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "|- BEIJING XFN-ASI...|        1|- BEIJING XFN-ASI...|- beijing xfn-asi...|beijing xfn asia ...|       -0.03125|\n",
      "|- Operating profi...|        1|- Operating profi...|- operating profi...|operating profit ...|            0.6|\n",
      "|- Provides summar...|        0|- Provides summar...|- provides summar...|provides summary ...|            0.0|\n",
      "|- So , the sales ...|        0|- So , the sales ...|- so , the sales ...|so the sales grow...|            0.1|\n",
      "|- UPM-Kymmene upg...|        1|- UPM-Kymmene upg...|- upm-kymmene upg...|upm kymmene upgra...|            0.0|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis main function\n",
    "!pip install textblob\n",
    "from pyspark.sql.types import FloatType\n",
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "sentiment_analysis_udf = udf(sentiment_analysis , FloatType())\n",
    "df  = df.withColumn(\"sentiment_score\", sentiment_analysis_udf( df['News_Cleaned'] ))\n",
    "df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29cffb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "|                News|Sentiment|       News_non_asci|   News_fixed_abbrev|        News_Cleaned|sentiment_score|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "|- BEIJING XFN-ASI...|        1|- BEIJING XFN-ASI...|- beijing xfn-asi...|beijing xfn asia ...|       -0.03125|\n",
      "|- Operating profi...|        1|- Operating profi...|- operating profi...|operating profit ...|            0.6|\n",
      "|- Provides summar...|        0|- Provides summar...|- provides summar...|provides summary ...|            0.0|\n",
      "|- So , the sales ...|        0|- So , the sales ...|- so , the sales ...|so the sales grow...|            0.1|\n",
      "|- UPM-Kymmene upg...|        1|- UPM-Kymmene upg...|- upm-kymmene upg...|upm kymmene upgra...|            0.0|\n",
      "|( ADP News ) - De...|        1|( ADP News ) - De...|( adp news ) - de...|adp news dec finn...|            0.0|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.3|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.3|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.3|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.0|\n",
      "|( ADP News ) - No...|        1|( ADP News ) - No...|( adp news ) - no...|adp news nov finn...|     0.28333333|\n",
      "|( ADP News ) - Oc...|        1|( ADP News ) - Oc...|( adp news ) - oc...|adp news oct finn...|            0.0|\n",
      "|( ADP News ) - Oc...|        1|( ADP News ) - Oc...|( adp news ) - oc...|adp news oct finn...|     0.28333333|\n",
      "|( ADP News ) - Oc...|        1|( ADP News ) - Oc...|( adp news ) - oc...|adp news oct finn...|    0.083333336|\n",
      "|( ADP News ) - Se...|        1|( ADP News ) - Se...|( adp news ) - se...|adp news sep finn...|            0.0|\n",
      "|( Filippova ) A t...|        1|( Filippova ) A t...|( filippova ) a t...|filippova trilate...|            0.0|\n",
      "|` By separating s...|        1|` By separating s...|` by separating s...|by separating sid...|            0.5|\n",
      "|` It is a testame...|        0|` It is a testame...|` it is a testame...|it is testament t...|            0.0|\n",
      "|` Our strategic c...|        1|` Our strategic c...|` our strategic c...|our strategic coo...|     0.13636364|\n",
      "|` Patja has worke...|        0|` Patja has worke...|` patja has worke...|patja has worked ...|      0.3181818|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67640ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- News: string (nullable = true)\n",
      " |-- Sentiment: string (nullable = true)\n",
      " |-- News_non_asci: string (nullable = true)\n",
      " |-- News_fixed_abbrev: string (nullable = true)\n",
      " |-- News_Cleaned: string (nullable = true)\n",
      " |-- sentiment_score: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "|                News|Sentiment|       News_non_asci|   News_fixed_abbrev|        News_Cleaned|sentiment_score|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "|- BEIJING XFN-ASI...|        1|- BEIJING XFN-ASI...|- beijing xfn-asi...|beijing xfn asia ...|       -0.03125|\n",
      "|- Operating profi...|        1|- Operating profi...|- operating profi...|operating profit ...|            0.6|\n",
      "|- Provides summar...|        0|- Provides summar...|- provides summar...|provides summary ...|            0.0|\n",
      "|- So , the sales ...|        0|- So , the sales ...|- so , the sales ...|so the sales grow...|            0.1|\n",
      "|- UPM-Kymmene upg...|        1|- UPM-Kymmene upg...|- upm-kymmene upg...|upm kymmene upgra...|            0.0|\n",
      "|( ADP News ) - De...|        1|( ADP News ) - De...|( adp news ) - de...|adp news dec finn...|            0.0|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.3|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.3|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.3|\n",
      "|( ADP News ) - Fe...|        1|( ADP News ) - Fe...|( adp news ) - fe...|adp news feb finn...|            0.0|\n",
      "|( ADP News ) - No...|        1|( ADP News ) - No...|( adp news ) - no...|adp news nov finn...|     0.28333333|\n",
      "|( ADP News ) - Oc...|        1|( ADP News ) - Oc...|( adp news ) - oc...|adp news oct finn...|            0.0|\n",
      "|( ADP News ) - Oc...|        1|( ADP News ) - Oc...|( adp news ) - oc...|adp news oct finn...|     0.28333333|\n",
      "|( ADP News ) - Oc...|        1|( ADP News ) - Oc...|( adp news ) - oc...|adp news oct finn...|    0.083333336|\n",
      "|( ADP News ) - Se...|        1|( ADP News ) - Se...|( adp news ) - se...|adp news sep finn...|            0.0|\n",
      "|( Filippova ) A t...|        1|( Filippova ) A t...|( filippova ) a t...|filippova trilate...|            0.0|\n",
      "|` By separating s...|        1|` By separating s...|` by separating s...|by separating sid...|            0.5|\n",
      "|` It is a testame...|        0|` It is a testame...|` it is a testame...|it is testament t...|            0.0|\n",
      "|` Our strategic c...|        1|` Our strategic c...|` our strategic c...|our strategic coo...|     0.13636364|\n",
      "|` Patja has worke...|        0|` Patja has worke...|` patja has worke...|patja has worked ...|      0.3181818|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"cast(sentiment_score as float) sentiment_score\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30271a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Classify the sentiment_score\n",
    "# <0 ==> Negative\n",
    "# =0 ==> Neutral\n",
    "# >0 ==> Posite \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd2ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
