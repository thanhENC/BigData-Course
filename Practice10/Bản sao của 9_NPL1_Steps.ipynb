{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dccc7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------+\n",
      "|user_id|review                                                  |\n",
      "+-------+--------------------------------------------------------+\n",
      "|1      |I really liked Bitcoin                                  |\n",
      "|2      |I would recommend this coin to my friends               |\n",
      "|3      |Crytocurencies was alright but I actually afraid of them|\n",
      "|4      |We believe in BNB and CZ                                |\n",
      "|5      |I am never buy that coin ever again                     |\n",
      "+-------+--------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('9_NPL_1').getOrCreate()\n",
    "df=spark.createDataFrame([(1,'I really liked Bitcoin '),\n",
    " (2,'I would recommend this coin to my friends'),\n",
    "(3,'Crytocurencies was alright but I actually afraid of them'),\n",
    "(4,'We believe in BNB and CZ'),\n",
    "(5,'I am never buy that coin ever again')],\n",
    " ['user_id','review'])\n",
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243f17ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------+------------------------------------------------------------------+\n",
      "|user_id|review                                                  |tokens                                                            |\n",
      "+-------+--------------------------------------------------------+------------------------------------------------------------------+\n",
      "|1      |I really liked Bitcoin                                  |[i, really, liked, bitcoin]                                       |\n",
      "|2      |I would recommend this coin to my friends               |[i, would, recommend, this, coin, to, my, friends]                |\n",
      "|3      |Crytocurencies was alright but I actually afraid of them|[crytocurencies, was, alright, but, i, actually, afraid, of, them]|\n",
      "|4      |We believe in BNB and CZ                                |[we, believe, in, bnb, and, cz]                                   |\n",
      "|5      |I am never buy that coin ever again                     |[i, am, never, buy, that, coin, ever, again]                      |\n",
      "+-------+--------------------------------------------------------+------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenization=Tokenizer(inputCol='review',outputCol='tokens')\n",
    "tokenized_df=tokenization.transform(df)\n",
    "tokenized_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfc3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc77a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------+-------------------------------------------+\n",
      "|user_id|tokens                                                            |refined_tokens                             |\n",
      "+-------+------------------------------------------------------------------+-------------------------------------------+\n",
      "|1      |[i, really, liked, bitcoin]                                       |[really, liked, bitcoin]                   |\n",
      "|2      |[i, would, recommend, this, coin, to, my, friends]                |[recommend, coin, friends]                 |\n",
      "|3      |[crytocurencies, was, alright, but, i, actually, afraid, of, them]|[crytocurencies, alright, actually, afraid]|\n",
      "|4      |[we, believe, in, bnb, and, cz]                                   |[believe, bnb, cz]                         |\n",
      "|5      |[i, am, never, buy, that, coin, ever, again]                      |[never, buy, coin, ever]                   |\n",
      "+-------+------------------------------------------------------------------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_df=stopword_removal.transform(tokenized_df)\n",
    "refined_df.select(['user_id','tokens','refined_tokens']).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3a1d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------+----------------------------------+\n",
      "|user_id|refined_tokens                             |features                          |\n",
      "+-------+-------------------------------------------+----------------------------------+\n",
      "|1      |[really, liked, bitcoin]                   |(16,[2,8,9],[1.0,1.0,1.0])        |\n",
      "|2      |[recommend, coin, friends]                 |(16,[0,3,14],[1.0,1.0,1.0])       |\n",
      "|3      |[crytocurencies, alright, actually, afraid]|(16,[4,5,10,13],[1.0,1.0,1.0,1.0])|\n",
      "|4      |[believe, bnb, cz]                         |(16,[1,11,12],[1.0,1.0,1.0])      |\n",
      "|5      |[never, buy, coin, ever]                   |(16,[0,6,7,15],[1.0,1.0,1.0,1.0]) |\n",
      "+-------+-------------------------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
    "cv_df=count_vec.fit(refined_df).transform(refined_df)\n",
    "cv_df.select(['user_id','refined_tokens','features']).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bb75527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coin',\n",
       " 'believe',\n",
       " 'liked',\n",
       " 'recommend',\n",
       " 'actually',\n",
       " 'afraid',\n",
       " 'buy',\n",
       " 'never',\n",
       " 'bitcoin',\n",
       " 'really',\n",
       " 'crytocurencies',\n",
       " 'bnb',\n",
       " 'cz',\n",
       " 'alright',\n",
       " 'friends',\n",
       " 'ever']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.fit(refined_df).vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a86ca916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------+--------------------------------------------------------+\n",
      "|user_id|refined_tokens                             |tf_features                                             |\n",
      "+-------+-------------------------------------------+--------------------------------------------------------+\n",
      "|1      |[really, liked, bitcoin]                   |(262144,[99172,132778,229264],[1.0,1.0,1.0])            |\n",
      "|2      |[recommend, coin, friends]                 |(262144,[68228,130047,163906],[1.0,1.0,1.0])            |\n",
      "|3      |[crytocurencies, alright, actually, afraid]|(262144,[126078,132975,171118,194136],[1.0,1.0,1.0,1.0])|\n",
      "|4      |[believe, bnb, cz]                         |(262144,[191454,211748,225157],[1.0,1.0,1.0])           |\n",
      "|5      |[never, buy, coin, ever]                   |(262144,[113673,163906,203802,213760],[1.0,1.0,1.0,1.0])|\n",
      "+-------+-------------------------------------------+--------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF,IDF\n",
    "hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features')\n",
    "hashing_df=hashing_vec.transform(refined_df)\n",
    "hashing_df.select(['user_id','refined_tokens','tf_features']).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "040d917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/27 11:57:16 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "+-------+--------------------------------------------------------------------------------------------------------------------+\n",
      "|user_id|tf_idf_features                                                                                                     |\n",
      "+-------+--------------------------------------------------------------------------------------------------------------------+\n",
      "|1      |(262144,[99172,132778,229264],[1.0986122886681098,1.0986122886681098,1.0986122886681098])                           |\n",
      "|2      |(262144,[68228,130047,163906],[1.0986122886681098,1.0986122886681098,0.6931471805599453])                           |\n",
      "|3      |(262144,[126078,132975,171118,194136],[1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098])|\n",
      "|4      |(262144,[191454,211748,225157],[1.0986122886681098,1.0986122886681098,1.0986122886681098])                          |\n",
      "|5      |(262144,[113673,163906,203802,213760],[1.0986122886681098,0.6931471805599453,1.0986122886681098,1.0986122886681098])|\n",
      "+-------+--------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vec=IDF(inputCol='tf_features',outputCol='tf_idf_features')\n",
    "tf_idf_df=tf_idf_vec.fit(hashing_df).transform(hashing_df)\n",
    "tf_idf_df.select(['user_id','tf_idf_features']).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baad0864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/27 11:58:52 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "+--------------------------------------------------------------------------------------------------------------------+\n",
      "|tf_idf_features                                                                                                     |\n",
      "+--------------------------------------------------------------------------------------------------------------------+\n",
      "|(262144,[99172,132778,229264],[1.0986122886681098,1.0986122886681098,1.0986122886681098])                           |\n",
      "|(262144,[68228,130047,163906],[1.0986122886681098,1.0986122886681098,0.6931471805599453])                           |\n",
      "|(262144,[126078,132975,171118,194136],[1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098])|\n",
      "|(262144,[191454,211748,225157],[1.0986122886681098,1.0986122886681098,1.0986122886681098])                          |\n",
      "|(262144,[113673,163906,203802,213760],[1.0986122886681098,0.6931471805599453,1.0986122886681098,1.0986122886681098])|\n",
      "+--------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf_df.select(['tf_idf_features']).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13746750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
