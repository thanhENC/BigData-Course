{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f70cc7",
   "metadata": {},
   "source": [
    "# Prepare the environment and collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa72d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- pdays: string (nullable = true)\n",
      " |-- previous: string (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Linear regression\").getOrCreate()\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.functions import mean, col\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "file_location = \"bank_deposit.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"False\"\n",
    "first_row_is_header = \"True\"\n",
    "df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".option(\"header\", first_row_is_header) \\\n",
    ".load(file_location)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f668d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "|age|job       |marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "|59 |admin.    |married|secondary|no     |2343   |yes    |no  |unknown|5  |may  |1042    |1       |-1   |0       |unknown |yes    |\n",
      "|56 |admin.    |married|secondary|no     |45     |no     |no  |unknown|5  |may  |1467    |1       |-1   |0       |unknown |yes    |\n",
      "|41 |technician|married|secondary|no     |1270   |yes    |no  |unknown|5  |may  |1389    |1       |-1   |0       |unknown |yes    |\n",
      "|55 |services  |married|secondary|no     |2476   |yes    |no  |unknown|5  |may  |579     |1       |-1   |0       |unknown |yes    |\n",
      "|54 |admin.    |married|tertiary |no     |184    |no     |no  |unknown|5  |may  |673     |2       |-1   |0       |unknown |yes    |\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d452fc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'int'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'string'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('deposit', 'string')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "#Identifying and assigning lists of variables\n",
    "float_vars=['age', 'balance', 'duration','campaign','pdays','previous']\n",
    "#Converting variables\n",
    "for column in float_vars:\n",
    " df=df.withColumn(column,df[column].cast(IntegerType()))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2507759",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63b222e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(df, CatCols, continuousCols, labelCol):\n",
    "  \n",
    "  indexers = [StringIndexer(inputCol=c, \n",
    "                            outputCol=\"{0}_indexed\".format(c)) for c in CatCols]\n",
    "\n",
    "  encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "              outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "              for indexer in indexers]\n",
    "\n",
    "\n",
    "  v = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                              + continuousCols, outputCol=\"features\")\n",
    "  \n",
    "  indexer = StringIndexer(inputCol=labelCol, outputCol='indexedLabel')\n",
    "\n",
    "  pipeline = Pipeline(stages = indexers + encoders + [v ] + [indexer])\n",
    "\n",
    "  model=pipeline.fit(df)\n",
    "    \n",
    "  data = model.transform(df)\n",
    "\n",
    "  data =  data.withColumn('label', col(labelCol))\n",
    "  \n",
    "  return  data.select('features', \n",
    "                     'indexedLabel', \n",
    "                     'label'), StringIndexer(inputCol='label').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b917726a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CatCols = ['job', 'marital', 'education', \n",
    "                      'default', 'housing', 'loan', \n",
    "                      'contact', 'poutcome']\n",
    "\n",
    "NumCols = ['age', 'balance', 'duration', \n",
    "               'campaign', 'pdays', 'previous']\n",
    "\n",
    "(df, labelindexer) = data_transformation(df, CatCols, NumCols, 'deposit')\n",
    "\n",
    "df.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b70777dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------------------+\n",
      "|            features|indexedLabel|label|     indexedFeatures|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|(30,[4,11,13,16,1...|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|(30,[3,11,14,16,1...|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|(30,[0,12,14,16,2...|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|(30,[0,11,14,16,2...|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|(30,[5,13,16,18,2...|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|(30,[4,12,13,16,1...|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=4).fit(df)\n",
    "\n",
    "featureIndexer.transform(df).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c78e762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ccb8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1257:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data splitting\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=10)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd5536",
   "metadata": {},
   "source": [
    "# Regression using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a0e8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "# Create initial Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\")\n",
    "\n",
    "# Train model with Training Data.\n",
    "dtModel = dt.fit(trainingData)\n",
    "\n",
    "# Make predictions on test data.\n",
    "predictions = dtModel.transform(testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "681453c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7947578853842736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.7464788732394366\n",
      "Recall = 0.8524124881740776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1881:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7980655405694509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the metrics. \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy = \",format(evaluator.evaluate(predictions)))\n",
    "\n",
    "predictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n",
    "\n",
    "# Instantiate metrics object \n",
    "metricsMulti = MulticlassMetrics(predictionAndLabel)\n",
    "metricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n",
    "\n",
    "precision = metricsMulti.precision(label=1) \n",
    "recall = metricsMulti.recall(label=1) \n",
    "\n",
    "\n",
    "print(\"Precision = \",precision) \n",
    "print(\"Recall =\" ,recall) \n",
    "print(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281d52",
   "metadata": {},
   "source": [
    "# Using k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1270877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for test set is 0.7947578853842736\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.7464788732394366\n",
      "Recall =  0.8524124881740776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1866:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7980655405694509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1, 2, 6, 10])\n",
    "             .addGrid(dt.maxBins, [20, 40, 80])\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"indexedLabel\")\n",
    "\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt, labelConverter]) \n",
    "kFold  = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, numFolds=2, \n",
    "                    parallelism=10, \n",
    "                    seed=100)\n",
    "kFoldModel = kFold .fit(trainingData)\n",
    "\n",
    "predictions = kFoldModel.transform(testData)\n",
    "\n",
    "# Evaluate the best model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", \n",
    "                                              predictionCol=\"prediction\", \n",
    "                                              metricName=\"accuracy\")\n",
    "print(\"Accuracy = \",format(evaluator.evaluate(predictions)))\n",
    "\n",
    "predictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n",
    "\n",
    "# Instantiate metrics object \n",
    "metricsMulti = MulticlassMetrics(predictionAndLabel)\n",
    "metricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n",
    "# Overall statistics \n",
    "precision = metricsMulti.precision(label=1) \n",
    "recall = metricsMulti.recall(label=1) \n",
    "\n",
    "print(\"Precision = \",precision) \n",
    "print(\"Recall = \" ,recall) \n",
    "print(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecb589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
