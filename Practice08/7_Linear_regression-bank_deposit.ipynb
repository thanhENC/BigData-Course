{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e969942e",
   "metadata": {},
   "source": [
    "The source code is developed by Thon-Da Nguyen Ph.D\n",
    "Course: Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f70cc7",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa72d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- pdays: string (nullable = true)\n",
      " |-- previous: string (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Linear regression\").getOrCreate()\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.functions import mean, col\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "file_location = \"bank_deposit.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"False\"\n",
    "first_row_is_header = \"True\"\n",
    "df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".option(\"header\", first_row_is_header) \\\n",
    ".load(file_location)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f668d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "|age|job       |marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "|59 |admin.    |married|secondary|no     |2343   |yes    |no  |unknown|5  |may  |1042    |1       |-1   |0       |unknown |yes    |\n",
      "|56 |admin.    |married|secondary|no     |45     |no     |no  |unknown|5  |may  |1467    |1       |-1   |0       |unknown |yes    |\n",
      "|41 |technician|married|secondary|no     |1270   |yes    |no  |unknown|5  |may  |1389    |1       |-1   |0       |unknown |yes    |\n",
      "|55 |services  |married|secondary|no     |2476   |yes    |no  |unknown|5  |may  |579     |1       |-1   |0       |unknown |yes    |\n",
      "|54 |admin.    |married|tertiary |no     |184    |no     |no  |unknown|5  |may  |673     |2       |-1   |0       |unknown |yes    |\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d452fc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'int'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'string'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('deposit', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "#Identifying and assigning lists of variables\n",
    "float_vars=['age', 'balance', 'duration','campaign','pdays','previous']\n",
    "#Converting variables\n",
    "for column in float_vars:\n",
    " df=df.withColumn(column,df[column].cast(IntegerType()))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2507759",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b222e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(df, CatCols, continuousCols, labelCol):\n",
    "  \n",
    "  indexers = [StringIndexer(inputCol=c, \n",
    "                            outputCol=\"{0}_indexed\".format(c)) for c in CatCols]\n",
    "\n",
    "  encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "              outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "              for indexer in indexers]\n",
    "\n",
    "\n",
    "  v = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                              + continuousCols, outputCol=\"features\")\n",
    "  \n",
    "  indexer = StringIndexer(inputCol=labelCol, outputCol='indexedLabel')\n",
    "\n",
    "  pipeline = Pipeline(stages = indexers + encoders + [v ] + [indexer])\n",
    "\n",
    "  model=pipeline.fit(df)\n",
    "    \n",
    "  data = model.transform(df)\n",
    "\n",
    "  data =  data.withColumn('label', col(labelCol))\n",
    "  \n",
    "  return  data.select('features', \n",
    "                     'indexedLabel', \n",
    "                     'label'), StringIndexer(inputCol='label').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b917726a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/15 18:21:41 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "CatCols = ['job', 'marital', 'education', \n",
    "                      'default', 'housing', 'loan', \n",
    "                      'contact', 'poutcome']\n",
    "\n",
    "NumCols = ['age', 'balance', 'duration', \n",
    "               'campaign', 'pdays', 'previous']\n",
    "\n",
    "(df, labelindexer) = data_transformation(df, CatCols, NumCols, 'deposit')\n",
    "\n",
    "df.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b70777dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------------------+\n",
      "|            features|indexedLabel|label|     indexedFeatures|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n",
      "|(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n",
      "|(30,[4,11,13,16,1...|         1.0|  yes|(30,[4,11,13,16,1...|\n",
      "|(30,[3,11,14,16,1...|         1.0|  yes|(30,[3,11,14,16,1...|\n",
      "|(30,[0,12,14,16,2...|         1.0|  yes|(30,[0,12,14,16,2...|\n",
      "|(30,[0,11,14,16,2...|         1.0|  yes|(30,[0,11,14,16,2...|\n",
      "|(30,[5,13,16,18,2...|         1.0|  yes|(30,[5,13,16,18,2...|\n",
      "|(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n",
      "|(30,[4,12,13,16,1...|         1.0|  yes|(30,[4,12,13,16,1...|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=4).fit(df)\n",
    "\n",
    "featureIndexer.transform(df).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c78e762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------+------------+-----+\n",
      "|features                                                                                                |indexedLabel|label|\n",
      "+--------------------------------------------------------------------------------------------------------+------------+-----+\n",
      "|(30,[3,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,59.0,2343.0,1042.0,1.0,-1.0])     |1.0         |yes  |\n",
      "|(30,[3,11,13,16,17,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,56.0,45.0,1467.0,1.0,-1.0])|1.0         |yes  |\n",
      "|(30,[2,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,41.0,1270.0,1389.0,1.0,-1.0])     |1.0         |yes  |\n",
      "|(30,[4,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,55.0,2476.0,579.0,1.0,-1.0])      |1.0         |yes  |\n",
      "|(30,[3,11,14,16,17,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,54.0,184.0,673.0,2.0,-1.0])|1.0         |yes  |\n",
      "|(30,[0,12,14,16,20,21,24,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,42.0,562.0,2.0,-1.0])                       |1.0         |yes  |\n",
      "|(30,[0,11,14,16,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,56.0,830.0,1201.0,1.0,-1.0])             |1.0         |yes  |\n",
      "|(30,[5,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,60.0,545.0,1030.0,1.0,-1.0])             |1.0         |yes  |\n",
      "|(30,[2,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.0,1.0,608.0,1.0,-1.0])         |1.0         |yes  |\n",
      "|(30,[4,12,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,28.0,5090.0,1297.0,3.0,-1.0])     |1.0         |yes  |\n",
      "+--------------------------------------------------------------------------------------------------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ccb8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 7808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 152:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 3354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Data splitting\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=10)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd5536",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a0e8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e1c98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", \n",
    "                               outputCol=\"predictedLabel\", \n",
    "                               labels=labelindexer.labels) \n",
    "\n",
    "pipeline = Pipeline(stages=[featureIndexer, lr, labelConverter])\n",
    "\n",
    "lrModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a059f6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 145:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|            features|indexedLabel|label|     indexedFeatures|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|(30,[0,11,13,16,1...|[-0.8537615416222...|[0.29864438411413...|       1.0|           yes|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|(30,[0,11,13,16,1...|[1.05708789470724...|[0.74213364500738...|       0.0|            no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|(30,[0,11,13,16,1...|[1.79830254601045...|[0.85794217949956...|       0.0|            no|\n",
      "|(30,[0,11,13,16,1...|         1.0|  yes|(30,[0,11,13,16,1...|[0.17261970311598...|[0.54304808482998...|       0.0|            no|\n",
      "|(30,[0,11,13,16,1...|         0.0|   no|(30,[0,11,13,16,1...|[1.19431615092198...|[0.76751211548388...|       0.0|            no|\n",
      "+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data \n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726be969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 205:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------+\n",
      "|            features|label|         probability|predictedLabel|\n",
      "+--------------------+-----+--------------------+--------------+\n",
      "|(30,[0,11,13,16,1...|  yes|[0.29864438411413...|           yes|\n",
      "|(30,[0,11,13,16,1...|  yes|[0.74213364500738...|            no|\n",
      "|(30,[0,11,13,16,1...|   no|[0.85794217949956...|            no|\n",
      "|(30,[0,11,13,16,1...|  yes|[0.54304808482998...|            no|\n",
      "|(30,[0,11,13,16,1...|   no|[0.76751211548388...|            no|\n",
      "+--------------------+-----+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\", \"label\", \"probability\", \"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5feba58f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute 'coefficients'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficients: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mlrModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefficients\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(lrModel\u001b[38;5;241m.\u001b[39mintercept))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute 'coefficients'"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5574511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10188:>                                                      (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.452546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"indexedLabel\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE): %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0a991e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10190:>                                                      (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.1777628286497135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"indexedLabel\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ebc00",
   "metadata": {},
   "source": [
    "# Using k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e5580cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10])\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "37034812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, lr, labelConverter]) \n",
    "kFold = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, numFolds=2, \n",
    "                    parallelism=10, seed=100)\n",
    "kFoldModel = kFold.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472fde75",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9b051672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10113:>                                                      (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------+\n",
      "|            features|label|         probability|predictedLabel|\n",
      "+--------------------+-----+--------------------+--------------+\n",
      "|(30,[0,11,13,16,1...|  yes|[0.33127668903429...|           yes|\n",
      "|(30,[0,11,13,16,1...|  yes|[0.70872079564193...|            no|\n",
      "|(30,[0,11,13,16,1...|   no|[0.82459930528361...|            no|\n",
      "|(30,[0,11,13,16,1...|  yes|[0.12758501942330...|           yes|\n",
      "|(30,[0,11,13,16,1...|  yes|[0.40607998217389...|           yes|\n",
      "+--------------------+-----+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = kFoldModel.transform(testData)\n",
    "\n",
    "predictions.select(\"features\", \"label\", \"probability\", \"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccfda5",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0d181b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m MulticlassClassificationEvaluator(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexedLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                               predictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                               metricName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m predictionAndLabel \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexedLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrdd\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Instantiate metrics object \u001b[39;00m\n\u001b[1;32m      8\u001b[0m metricsMulti \u001b[38;5;241m=\u001b[39m MulticlassMetrics(predictionAndLabel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", \n",
    "                                              predictionCol=\"prediction\", \n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "predictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n",
    "\n",
    "# Instantiate metrics object \n",
    "metricsMulti = MulticlassMetrics(predictionAndLabel)\n",
    "metricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n",
    "# Overall statistics \n",
    "\n",
    "precision = metricsMulti.precision(label=1) \n",
    "recall = metricsMulti.recall(label=1) \n",
    "#f1Score = metricsMulti.fMeasure() \n",
    "print(\"Evaluation Metrics (Linear Regression)\")\n",
    "\n",
    "print(\"Accuracy = \",format(evaluator.evaluate(predictions)))\n",
    "print(\"Precision = \", precision) \n",
    "print(\"Recall = \", recall) \n",
    "print(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681453c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
